{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecb770f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import gymnasium_2048\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from simulations.run import create_dataset, preprocess_dataset\n",
    "from simulations.base_agents import NNAgent\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62875b2b",
   "metadata": {},
   "source": [
    "## Создание датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00cd1ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV_ID = \"gymnasium_2048/TwentyFortyEight-v0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5183e339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(16, 128, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(128, 128, kernel_size=(2, 2), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make(ENV_ID)\n",
    "agent = NNAgent(env)\n",
    "agent.load_weights('../weights_ep5000.pth')\n",
    "agent.model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c355c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [03:22<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Датасет сохранён в: ../nn_expert_dataset1.pkl\n",
      "Собрано 86431 ходов из 200 эпизодов.\n"
     ]
    }
   ],
   "source": [
    "dataset, scores = create_dataset(\n",
    "    env, \n",
    "    agent,\n",
    "    n_episodes=200,\n",
    "    visualize=False,\n",
    "    on_illegal='ask', \n",
    "    save_path=['../nn_expert_dataset.pkl']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0aa3f22b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(6352.3)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39c62ca",
   "metadata": {},
   "source": [
    "## Загрузка датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4f9f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../nn_expert_dataset.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bf393be2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['boards', 'features', 'actions', 'rewards', 'episode_ids', 'step_ids', 'Q-values'])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f0e446a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_narrow = [\n",
    "    'snake_weighted_sum',            \n",
    "    'monotonicity',   \n",
    "    'tile_sum',    \n",
    "    'potential_merges', \n",
    "    'corner_weighted_sum',\n",
    "    'num_empty',\n",
    "    'max_tile',\n",
    "    'smoothness',\n",
    "    'corner_sum',\n",
    "    'second_max_tile',\n",
    "    'edge_occupancy',   \n",
    "    'conv_vert_gradient', \n",
    "    'conv_horiz_gradient',\n",
    "    'entropy'  \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8215c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of the dataset: 232452\n"
     ]
    }
   ],
   "source": [
    "# загрузка данных по 100 лучшим партиям с расширением\n",
    "features, target = preprocess_dataset(\n",
    "    \"../nn_expert_dataset.pkl\", \n",
    "    keep_best=100, \n",
    "    features_list=features_narrow, \n",
    "    expand=True, \n",
    "    normalize=True\n",
    ")\n",
    "dataset = {\n",
    "    'features': features, \n",
    "    'target': target\n",
    "}\n",
    "\n",
    "print(f'length of the dataset: {len(features)}')\n",
    "with open('../nn_expert_dataset_expanded.pkl', \"wb\") as f:\n",
    "    pickle.dump(dataset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6cf83179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Information for level easy\n",
      "condition: (count_empty >= 8)\n",
      "length of the expanded dataset: 15079\n",
      "--------------------------------------------------\n",
      "Information for level medium\n",
      "condition: (count_empty < 8) & (count_empty >= 4)\n",
      "length of the expanded dataset: 116335\n",
      "--------------------------------------------------\n",
      "Information for level hard\n",
      "condition: (count_empty < 8)\n",
      "length of the expanded dataset: 107098\n"
     ]
    }
   ],
   "source": [
    "# загрузка данных по каждой сложности отдельно (в зависимости от количества свободных ячеек на поле)\n",
    "(\n",
    "    (features_easy, target_easy), \n",
    "    (features_medium, target_medium), \n",
    "    (features_hard, target_hard)\n",
    ") = preprocess_dataset(\n",
    "    \"../nn_expert_dataset.pkl\", \n",
    "    keep_best=100, \n",
    "    features_list=features_narrow, \n",
    "    expand=True, \n",
    "    transform='divide_by_empty',\n",
    "    normalize=True\n",
    ")\n",
    "\n",
    "condition_dict = {\n",
    "    'easy': {\n",
    "        'length': len(features_easy), \n",
    "        'condition': '(count_empty >= 8)'\n",
    "    }, \n",
    "    'medium': {\n",
    "        'length': len(features_medium), \n",
    "        'condition': '(count_empty < 8) & (count_empty >= 4)'\n",
    "    }, \n",
    "    'hard': {\n",
    "        'length': len(features_hard), \n",
    "        'condition': '(count_empty < 8)'\n",
    "    }, \n",
    "}\n",
    "\n",
    "for key, val in condition_dict.items():\n",
    "    print('-' * 50)\n",
    "    print(f'Information for level {key}')\n",
    "    conditioon = val['condition']\n",
    "    print(f'condition: {conditioon}')\n",
    "    length = val['length']\n",
    "    print(f'length of the expanded dataset: {length}')\n",
    "    \n",
    "    \n",
    "dataset = {\n",
    "    'features_easy': features_easy, \n",
    "    'target_easy': target_easy, \n",
    "    'features_medium': features_medium, \n",
    "    'target_medium': target_medium, \n",
    "    'features_hard': features_hard, \n",
    "    'target_hard': target_hard \n",
    "}\n",
    "\n",
    "with open('../nn_expert_dataset_expanded_level.pkl', \"wb\") as f:\n",
    "    pickle.dump(dataset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15d561d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_2048",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
